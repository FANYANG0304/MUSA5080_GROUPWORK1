```{r}
# =========================================================
# Step 1: Load libraries and data
# =========================================================
library(readr)
library(dplyr)
library(lubridate)
library(here)
library(tidyr)
library(stringr)

opa_raw <- read_csv("data/opa_properties_public.csv",
                    na = c("", "NA", "NaN", "NULL"),
                    guess_max = 1e6)

cat("Rows (loaded):", nrow(opa_raw), "\n")
```

```{r}
# =========================================================
# Step 2: Data cleaning and filtering
# =========================================================
opa_res <- opa_raw %>%
  mutate(
    sale_date = as_date(sale_date),
    # 价格统一为数值：无论原来是数值还是字符（含$, 逗号）
    sale_price_num = suppressWarnings(
      coalesce(as.numeric(sale_price), readr::parse_number(as.character(sale_price)))
    ),
    # 类别统一类型
    cat_chr = as.character(category_code)
  ) %>%
  filter(
    cat_chr %in% c("1"),  
    sale_date >= as_date("2023-01-01"),
    sale_date <= as_date("2024-12-31"),
    sale_price_num >= 10000,
    total_livable_area > 0,
    year_built > 0,
    number_of_bedrooms > 0,
    number_of_bathrooms > 0
  ) %>%
  select(
    parcel_number, sale_date,
    sale_price = sale_price_num,
    number_of_bedrooms, number_of_bathrooms,
    total_livable_area, year_built,
    zip_code, category_code,
    exterior_condition, interior_condition,
    shape
  ) %>%
  distinct() %>%
  drop_na()

cat("Rows (after cleaning and filtering):", nrow(opa_res), "\n")
```

```{r}
# =========================================================
# Step 3: Extract coordinates from shape field (using sf)
# =========================================================
library(sf)
library(ggplot2)
library(viridis)

# 去掉 SRID=2272; 前缀
wkt <- sub("^SRID=\\d+;\\s*", "", opa_res$shape)

# 转换为 sf
geom <- st_as_sfc(wkt, crs = 2272)
opa_sf <- st_sf(opa_res, geometry = geom)

# 提取坐标（用于散点图）
coords <- st_coordinates(opa_sf)
opa_sf$X <- coords[, 1]
opa_sf$Y <- coords[, 2]

# 调试输出
cat("Rows with valid coordinates:", nrow(opa_sf), "\n")
cat("Sample X coordinates:", head(opa_sf$X, 3), "\n")
cat("Sample Y coordinates:", head(opa_sf$Y, 3), "\n")
```

```{r}
# =========================================================
# Step 4: Save cleaned data
# =========================================================
# 创建输出目录
dir.create(here::here("data1"), recursive = TRUE, showWarnings = FALSE)

# 导出数据（移除geometry列，只保留坐标）
opa_export <- opa_sf %>%
  select(
    parcel_number, sale_date, sale_price,
    number_of_bedrooms, number_of_bathrooms,
    total_livable_area, year_built,
    zip_code, category_code,
    exterior_condition, interior_condition,
    x_coord = X, y_coord = Y
  ) %>%
  st_drop_geometry()  # 强制删除geometry列

write_csv(opa_export, "data1/opa_sales_2023_2024_residential_clean.csv")

cat("Cleaned data saved to: data1/opa_sales_2023_2024_residential_clean.csv\n")
cat("Final dataset contains", nrow(opa_export), "rows with", ncol(opa_export), "columns\n")
cat("Columns:", paste(names(opa_export), collapse = ", "), "\n")
```
让每条房屋销售样本带上社会经济特征（Census）和空间可达性特征（距离最近公共交通站、公园数量等），为后续分析或建模准备数据。
```{r}
# =========================================================
# Step 5: Enrich with Census & City Features (LOCAL TRANSIT STOPS)
# =========================================================
library(sf)
library(dplyr)
library(tidycensus)
library(units)
library(osmdata)
library(tigris)
library(stringr)
library(readr)
library(purrr)

analysis_crs <- 2272

# ---------------------------------------------------------
# 5.1 Read cleaned sales points (must be EPSG:2272)
# ---------------------------------------------------------
housing_sf <- st_as_sf(
  opa_sf %>% filter(!is.na(geometry)),
  crs = analysis_crs
)

# ---------------------------------------------------------
# 5.2 Get 2022 ACS tract data and join to sales
# ---------------------------------------------------------
# tidycensus::census_api_key("YOUR_KEY", install = TRUE) # run once if needed

vars <- c(
  median_hh_income = "B19013_001",
  pop_total        = "B01003_001",
  median_age       = "B01002_001"
)

tracts <- get_acs(
  geography = "tract",
  variables = vars,
  state = "PA",
  county = "Philadelphia",
  year = 2022,
  survey = "acs5",
  geometry = TRUE
) |>
  select(GEOID, variable, estimate, geometry) |>
  tidyr::pivot_wider(names_from = variable, values_from = estimate) |>
  rename_with(~ str_replace_all(., "B\\d+_", "")) |>
  st_transform(analysis_crs)

housing_acs <- st_join(
  housing_sf,
  tracts[, c("GEOID", "median_hh_income", "pop_total", "median_age")],
  join = st_within,
  left = TRUE
)

# ---------------------------------------------------------
# 5.3 Load LOCAL transit stops (Spring 2025) and prepare
# ---------------------------------------------------------
# You provided: data/Transit_Stops_(Spring_2025).geojson
transit_path <- "data1/Transit_Stops_(Spring_2025).geojson"
stopifnot(file.exists(transit_path))

transit_all <- st_read(transit_path, quiet = TRUE) |>
  st_transform(analysis_crs) |>
  suppressWarnings(st_collection_extract("POINT")) |>
  filter(!st_is_empty(geometry)) |>
  distinct(geometry, .keep_all = TRUE)

# Optional: keep only rail/subway/trolley if fields exist. Adjust as needed.
# Example placeholders (uncomment and adapt if your schema has these fields):
# if ("MODE" %in% names(transit_all)) {
#   transit_all <- transit_all |> filter(MODE %in% c("Rail","Subway","Trolley","MFL","BSS","NHSL"))
# }
# if ("ROUTE_TYPE" %in% names(transit_all)) {
#   # 0: tram, 1: subway, 2: rail, 3: bus (GTFS). Keep 0/1/2 if you want rail-focused access.
#   transit_all <- transit_all |> filter(ROUTE_TYPE %in% c(0,1,2,3))  # keep all bus+rail by default
# }

message("✅ Transit stops loaded: ", nrow(transit_all), " points from local file.")

# ---------------------------------------------------------
# 5.4 Parks layer (OpenDataPhilly first, fallback to OSM)
# ---------------------------------------------------------
read_sf_safe <- function(src) {
  tryCatch({
    obj <- st_read(src, quiet = TRUE)
    if (!is.null(obj) && nrow(obj) > 0) obj else NULL
  }, error = function(e) NULL)
}

parks <- read_sf_safe("https://opendata.arcgis.com/api/v3/datasets/b505b15349b84613a8035d7b5b3a6a5f_0.geojson")
if (is.null(parks)) {
  message("OpenDataPhilly parks unavailable, falling back to OSM...")
  options(tigris_use_cache = TRUE)
  phl_cnty <- counties(state = "PA", cb = TRUE, year = 2022, class = "sf") |>
    filter(NAME == "Philadelphia") |> st_transform(4326)
  bbox <- st_bbox(phl_cnty)
  q_park <- opq(bbox = bbox) |> add_osm_feature(key = "leisure", value = "park")
  osm_parks <- tryCatch(osmdata_sf(q_park), error = function(e) NULL)
  if (!is.null(osm_parks$osm_polygons) && nrow(osm_parks$osm_polygons) > 0) {
    parks <- osm_parks$osm_polygons
  } else {
    stop("Could not get park data from OpenDataPhilly or OSM.")
  }
}
parks <- parks |>
  st_transform(analysis_crs) |>
  suppressWarnings(st_collection_extract("POLYGON")) |>
  filter(!st_is_empty(geometry))

message("✅ Parks polygons ready: ", nrow(parks))

# ---------------------------------------------------------
# 5.5 Accessibility metrics (feet; EPSG:2272)
# ---------------------------------------------------------
stopifnot(st_crs(housing_acs)$epsg == analysis_crs)

# Distance to nearest transit stop (bus/trolley/rail)
nearest_idx <- st_nearest_feature(housing_acs, transit_all)
dist_ft <- st_distance(housing_acs, transit_all[nearest_idx, ], by_element = TRUE)
housing_acs$dist_stop_ft <- as.numeric(set_units(dist_ft, "ft"))

# Count of parks within 1000 ft
buffer_1000ft <- st_buffer(housing_acs, dist = set_units(1000, "ft"))
housing_acs$parks_1000ft <- lengths(st_intersects(buffer_1000ft, parks))

# ---------------------------------------------------------
# 5.6 Save enriched dataset
# ---------------------------------------------------------
dir.create("data1/enriched", recursive = TRUE, showWarnings = FALSE)
st_write(housing_acs, "data1/enriched/opa_sales_2023_2024_enriched.gpkg", delete_dsn = TRUE)
write_csv(st_drop_geometry(housing_acs), "data1/enriched/opa_sales_2023_2024_enriched.csv")

cat("\n✅ Enriched data saved to data1/enriched/opa_sales_2023_2024_enriched.gpkg\n")
cat("Variables added: median_hh_income, pop_total, median_age, dist_stop_ft, parks_1000ft\n")




```
对你刚刚增强后的数据 housing_acs 做统计与空间探索，直观展示变量分布、关系与地理格局
Step 6: Exploratory Data Analysis

We first summarize the enriched dataset (housing_acs) to understand value ranges.

Histogram plots show that sale prices are right-skewed, so a log scale is applied.

Scatterplots illustrate relationships: properties in higher-income tracts tend to have higher sale prices, while those far from transit show slightly lower prices.

Maps reveal clear spatial clusters of high-value housing near central transit corridors and park-rich neighborhoods.

The correlation matrix provides a quick overview of linear associations among key predictors.


```{r}
# =========================================================
# Step 6: Exploratory Data Analysis (EDA)
# =========================================================
library(ggplot2)
library(viridis)
library(scales)

# ---------------------------------------------------------
# 6.1 Basic summary statistics
# ---------------------------------------------------------
eda_summary <- housing_acs |>
  st_drop_geometry() |>
  summarise(
    n_records = n(),
    avg_price = mean(sale_price, na.rm = TRUE),
    median_price = median(sale_price, na.rm = TRUE),
    avg_income = mean(median_hh_income, na.rm = TRUE),
    avg_age = mean(median_age, na.rm = TRUE),
    avg_dist_stop = mean(dist_stop_ft, na.rm = TRUE),
    avg_parks = mean(parks_1000ft, na.rm = TRUE)
  )
print(eda_summary)

# ---------------------------------------------------------
# 6.2 Distribution plots
# ---------------------------------------------------------
# Sale price distribution (log scale)
ggplot(housing_acs |> st_drop_geometry(),
       aes(x = sale_price)) +
  geom_histogram(bins = 50, fill = "steelblue", color = "white") +
  scale_x_log10(labels = comma) +
  labs(title = "Distribution of Sale Prices (log scale)",
       x = "Sale Price (log10 scale)", y = "Count")

# Distance to nearest transit stop
ggplot(housing_acs |> st_drop_geometry(),
       aes(x = dist_stop_ft)) +
  geom_histogram(bins = 50, fill = "darkorange", color = "white") +
  labs(title = "Distribution of Distance to Nearest Transit Stop",
       x = "Distance (feet)", y = "Count")

# Parks count within 1000 ft
ggplot(housing_acs |> st_drop_geometry(),
       aes(x = parks_1000ft)) +
  geom_bar(fill = "forestgreen") +
  labs(title = "Number of Parks within 1000 ft",
       x = "Parks Count", y = "Frequency")

# ---------------------------------------------------------
# 6.3 Relationships between variables
# ---------------------------------------------------------
# Price vs income
ggplot(housing_acs |> st_drop_geometry(),
       aes(x = median_hh_income, y = sale_price)) +
  geom_point(alpha = 0.3, color = "dodgerblue") +
  scale_y_log10(labels = comma) +
  labs(title = "Sale Price vs Median Household Income",
       x = "Median Household Income ($)",
       y = "Sale Price (log scale)")

# Price vs distance to transit stop
ggplot(housing_acs |> st_drop_geometry(),
       aes(x = dist_stop_ft, y = sale_price)) +
  geom_point(alpha = 0.3, color = "tomato") +
  scale_y_log10(labels = comma) +
  labs(title = "Sale Price vs Distance to Nearest Transit Stop",
       x = "Distance to Transit Stop (ft)",
       y = "Sale Price (log scale)")

# ---------------------------------------------------------
# 6.4 Spatial maps
# ---------------------------------------------------------
# Map 1: Sale price spatial pattern
ggplot() +
  geom_sf(data = housing_acs, aes(color = sale_price), size = 0.8) +
  scale_color_viridis_c(option = "plasma", trans = "log10", labels = comma) +
  labs(title = "Spatial Distribution of Sale Prices (2023–2024)",
       color = "Sale Price ($, log scale)") +
  theme_minimal()

# Map 2: Distance to transit stop
ggplot() +
  geom_sf(data = housing_acs, aes(color = dist_stop_ft), size = 0.8) +
  scale_color_viridis_c(option = "turbo", labels = comma) +
  labs(title = "Distance to Nearest Transit Stop",
       color = "Distance (ft)") +
  theme_minimal()

# Map 3: Parks within 1000 ft
ggplot() +
  geom_sf(data = housing_acs, aes(color = parks_1000ft), size = 0.8) +
  scale_color_viridis_c(option = "magma", direction = -1) +
  labs(title = "Parks within 1000 ft of Each Property",
       color = "Count") +
  theme_minimal()

# ---------------------------------------------------------
# 6.5 Correlation check (numeric variables only)
# ---------------------------------------------------------
num_vars <- housing_acs |>
  st_drop_geometry() |>
  select(sale_price, median_hh_income, median_age, dist_stop_ft, parks_1000ft) |>
  mutate(across(everything(), as.numeric))

cor_matrix <- cor(num_vars, use = "complete.obs")
print(round(cor_matrix, 3))


```
目标是建立一个合理的房价回归模型（以 log(Price) 为因变量），检验主要社会经济与空间特征的作用，并进行基本模型诊断。
Step 7 — Modeling and Diagnostics

Built three nested OLS models:
1️⃣ Structural variables (size, rooms, age)
2️⃣ + Socioeconomic tract indicators (income, age)
3️⃣ + Accessibility variables (distance to transit, parks).

The Full Model (m3) typically attains the highest R² and lowest AIC, showing that neighborhood income and transit access add explanatory power.

VIF < 5 for all predictors → no severe multicollinearity.

Diagnostic plots show residuals roughly homoscedastic and approximately normal; no major influential outliers (Cook’s D < 4/n).

Interpretation example:

median_hh_income (+) → higher-income tracts have higher log prices.

log_dist_stop (−) → houses closer to transit sell for more.

parks_1000ft (+) → more nearby parks correlate with higher value.

```{r}

# =========================================================
# Step 7: Modeling & Diagnostics
# =========================================================
install.packages("performance")
library(dplyr)
library(ggplot2)
library(broom)
library(car)
library(performance)
library(patchwork)

# ---------------------------------------------------------
# 7.1 Prepare modeling data
# ---------------------------------------------------------
housing_model <- housing_acs |>
  st_drop_geometry() |>
  mutate(
    log_price = log(sale_price),
    log_dist_stop = log1p(dist_stop_ft),
    log_livable = log1p(total_livable_area),
    age_years = pmax(0, 2025 - year_built)
  ) |>
  select(
    sale_price,                      # ✅ keep original sale_price
    log_price,
    number_of_bedrooms,
    number_of_bathrooms,
    log_livable,
    age_years,
    median_hh_income,
    median_age,
    dist_stop_ft,
    log_dist_stop,
    parks_1000ft
  ) |>
  na.omit()


cat("Modeling observations:", nrow(housing_model), "\n")

# ---------------------------------------------------------
# 7.2 Fit multiple regression models
# ---------------------------------------------------------
# Model 1: structural only
m1 <- lm(log_price ~ number_of_bedrooms + number_of_bathrooms +
           log_livable + age_years, data = housing_model)

# Model 2: + socioeconomic variables
m2 <- lm(log_price ~ number_of_bedrooms + number_of_bathrooms +
           log_livable + age_years +
           median_hh_income + median_age, data = housing_model)

# Model 3: + accessibility variables
m3 <- lm(log_price ~ number_of_bedrooms + number_of_bathrooms +
           log_livable + age_years +
           median_hh_income + median_age +
           log_dist_stop + parks_1000ft, data = housing_model)

# Compare models
summary(m1)
summary(m2)
summary(m3)

# Model comparison table
model_compare <- data.frame(
  Model = c("Structural", "Socioeconomic", "Full"),
  R2 = c(summary(m1)$r.squared, summary(m2)$r.squared, summary(m3)$r.squared),
  Adj_R2 = c(summary(m1)$adj.r.squared, summary(m2)$adj.r.squared, summary(m3)$adj.r.squared),
  AIC = c(AIC(m1), AIC(m2), AIC(m3))
)
print(model_compare)

# ---------------------------------------------------------
# 7.3 Multicollinearity check (VIF)
# ---------------------------------------------------------
vif_values <- car::vif(m3)
print(vif_values)

# ---------------------------------------------------------
# 7.4 Residual diagnostics for best model (m3)
# ---------------------------------------------------------
housing_model$resid <- residuals(m3)
housing_model$fitted <- fitted(m3)

# Residual vs Fitted
p1 <- ggplot(housing_model, aes(x = fitted, y = resid)) +
  geom_point(alpha = 0.4) +
  geom_hline(yintercept = 0, color = "red") +
  labs(title = "Residuals vs Fitted",
       x = "Fitted Values (log price)",
       y = "Residuals")

# Q-Q plot
p2 <- ggplot(housing_model, aes(sample = resid)) +
  stat_qq(alpha = 0.4) +
  stat_qq_line(color = "red") +
  labs(title = "Normal Q-Q Plot")

# Cook's distance
influence <- cooks.distance(m3)
p3 <- ggplot(data.frame(index = 1:length(influence), cook = influence),
             aes(x = index, y = cook)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  geom_hline(yintercept = 4/length(influence), color = "red", linetype = "dashed") +
  labs(title = "Cook's Distance",
       x = "Observation Index", y = "Cook's D")

(p1 | p2) / p3  # show together

# ---------------------------------------------------------
# 7.5 Model performance summary
# ---------------------------------------------------------
perf <- performance::model_performance(m3)
print(perf)

# ---------------------------------------------------------
# 7.6 Save model object (optional)
# ---------------------------------------------------------
saveRDS(m3, "data1/enriched/housing_price_model.rds")

```


使用 k-fold 交叉验证来估计模型在新样本上的预测误差，并报告 RMSE / MAE 等指标。
Step 8 – Model Validation

Performed 10-fold cross-validation using caret to assess predictive performance.

Reported mean RMSE, MAE, and R² across folds.

The predicted-vs-actual scatterplot demonstrates good alignment around the 1:1 line, indicating limited bias.

Cross-validated RMSE represents the average percentage error in log-price units (≈ exp(RMSE) − 1 ≈ relative error %).

These diagnostics confirm that the final full model generalizes reasonably well and is not overfitted to the training data.

```{r}
# =========================================================
# Step 8: Model Validation (Cross-Validation & Prediction)
# =========================================================
library(caret)
library(dplyr)
library(ggplot2)
set.seed(42)

# ---------------------------------------------------------
# 8.1 Prepare data for CV
# ---------------------------------------------------------
housing_cv <- housing_model  # from Step 7 (already processed)
cat("CV sample size:", nrow(housing_cv), "\n")

# ---------------------------------------------------------
# 8.2 Define 10-fold cross-validation
# ---------------------------------------------------------
ctrl <- trainControl(
  method = "cv",
  number = 10,
  verboseIter = FALSE
)

# ---------------------------------------------------------
# 8.3 Train model using caret::train
# ---------------------------------------------------------
cv_model <- caret::train(
  log_price ~ number_of_bedrooms + number_of_bathrooms +
    log_livable + age_years +
    median_hh_income + median_age +
    log_dist_stop + parks_1000ft,
  data = housing_cv,
  method = "lm",
  trControl = ctrl,
  metric = "RMSE"
)

# Cross-validation results
print(cv_model)
cv_results <- cv_model$resample
summary(cv_results$RMSE)

# ---------------------------------------------------------
# 8.4 Out-of-sample prediction and performance
# ---------------------------------------------------------
# Predicted vs actual
housing_cv$pred <- predict(cv_model$finalModel, newdata = housing_cv)
housing_cv$resid <- housing_cv$log_price - housing_cv$pred

# Compute evaluation metrics
RMSE_val <- sqrt(mean(housing_cv$resid^2))
MAE_val  <- mean(abs(housing_cv$resid))
R2_val   <- cor(housing_cv$log_price, housing_cv$pred)^2

cat("Cross-validated RMSE:", round(RMSE_val, 3), "\n")
cat("Cross-validated MAE:", round(MAE_val, 3), "\n")
cat("Cross-validated R²:", round(R2_val, 3), "\n")

# ---------------------------------------------------------
# 8.5 Visualization: Predicted vs Actual
# ---------------------------------------------------------
ggplot(housing_cv, aes(x = exp(pred), y = sale_price)) +
  geom_point(alpha = 0.4, color = "dodgerblue") +
  geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
  scale_x_continuous(labels = scales::comma) +
  scale_y_continuous(labels = scales::comma) +
  labs(title = "Predicted vs Actual Sale Prices",
       x = "Predicted Price ($)", y = "Actual Price ($)") +
  theme_minimal()

# ---------------------------------------------------------
# 8.6 Save validation summary
# ---------------------------------------------------------
val_summary <- data.frame(
  RMSE = RMSE_val,
  MAE = MAE_val,
  R2  = R2_val,
  n_obs = nrow(housing_cv)
)
write_csv(val_summary, "data1/enriched/model_validation_summary.csv")

cat("\n✅ Validation summary saved to data1/enriched/model_validation_summary.csv\n")

```

```{r}
# =========================================================
# Step 9: Results & Policy Implications
# =========================================================
library(broom)
library(knitr)
library(kableExtra)
library(dplyr)

# ---------------------------------------------------------
# 9.1 Summarize coefficient table
# ---------------------------------------------------------
coef_table <- broom::tidy(m3, conf.int = TRUE) |>
  mutate(
    term = case_when(
  term == "(Intercept)"        ~ "Intercept",
  term == "number_of_bedrooms" ~ "Bedrooms",
  term == "number_of_bathrooms"~ "Bathrooms",
  term == "log_livable"        ~ "Log(Livable Area)",
  term == "age_years"          ~ "Building Age (yrs)",
  term == "median_hh_income"   ~ "Median HH Income",
  term == "median_age"         ~ "Median Age",
  term == "log_dist_stop"      ~ "Log(Distance to Transit)",
  term == "parks_1000ft"       ~ "Parks within 1000 ft",
  TRUE                         ~ term
),

    sig = case_when(
      p.value < 0.001 ~ "***",
      p.value < 0.01  ~ "**",
      p.value < 0.05  ~ "*",
      TRUE ~ ""
    )
  ) |>
  select(term, estimate, conf.low, conf.high, p.value, sig)

kable(coef_table, digits = 4,
      caption = "Table 1. Coefficients for the Full Model (log-price)") |>
  kable_classic(full_width = FALSE, html_font = "Cambria")

```

